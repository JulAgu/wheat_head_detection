{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/juagudelo/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-11-21 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA T1000 8GB, 7975MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.2k/49.2k [00:00<00:00, 4.94MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134k/134k [00:00<00:00, 4.86MB/s]\n",
      "/home/juagudelo/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "image 1/2: 720x1280 2 persons, 1 tie, 1 cell phone\n",
      "image 2/2: 1080x810 4 persons, 1 bus\n",
      "Speed: 20.7ms pre-process, 25.2ms inference, 2.0ms NMS per image at shape (2, 3, 640, 640)\n",
      "Saved 2 images to \u001b[1mruns/detect/exp\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744.907715</td>\n",
       "      <td>47.730957</td>\n",
       "      <td>1142.076172</td>\n",
       "      <td>716.559448</td>\n",
       "      <td>0.867366</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127.860870</td>\n",
       "      <td>197.634583</td>\n",
       "      <td>845.973877</td>\n",
       "      <td>710.378113</td>\n",
       "      <td>0.637458</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.277222</td>\n",
       "      <td>439.579651</td>\n",
       "      <td>498.367310</td>\n",
       "      <td>708.055603</td>\n",
       "      <td>0.635027</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>594.006104</td>\n",
       "      <td>376.740356</td>\n",
       "      <td>635.635010</td>\n",
       "      <td>437.111206</td>\n",
       "      <td>0.277625</td>\n",
       "      <td>67</td>\n",
       "      <td>cell phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xmin        ymin         xmax        ymax  confidence  class  \\\n",
       "0  744.907715   47.730957  1142.076172  716.559448    0.867366      0   \n",
       "1  127.860870  197.634583   845.973877  710.378113    0.637458      0   \n",
       "2  441.277222  439.579651   498.367310  708.055603    0.635027     27   \n",
       "3  594.006104  376.740356   635.635010  437.111206    0.277625     67   \n",
       "\n",
       "         name  \n",
       "0      person  \n",
       "1      person  \n",
       "2         tie  \n",
       "3  cell phone  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
    "\n",
    "# Images\n",
    "for f in \"zidane.jpg\", \"bus.jpg\":\n",
    "    torch.hub.download_url_to_file(\"https://ultralytics.com/images/\" + f, f)  # download 2 images\n",
    "im1 = Image.open(\"zidane.jpg\")  # PIL image\n",
    "im2 = cv2.imread(\"bus.jpg\")[..., ::-1]  # OpenCV image (BGR to RGB)\n",
    "\n",
    "# Inference\n",
    "results = model([im1, im2], size=640)  # batch of images\n",
    "\n",
    "# Results\n",
    "results.print()\n",
    "results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # im1 predictions (tensor)\n",
    "results.pandas().xyxy[0]  # im1 predictions (pandas)\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/juagudelo/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-11-21 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA T1000 8GB, 7975MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "/home/juagudelo/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>487.388611</td>\n",
       "      <td>46.844364</td>\n",
       "      <td>792.064331</td>\n",
       "      <td>575.851929</td>\n",
       "      <td>0.899190</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>781.720581</td>\n",
       "      <td>241.722565</td>\n",
       "      <td>889.911133</td>\n",
       "      <td>379.067932</td>\n",
       "      <td>0.792831</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>434.312683</td>\n",
       "      <td>5.349050</td>\n",
       "      <td>620.991882</td>\n",
       "      <td>156.600708</td>\n",
       "      <td>0.777548</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>538.909790</td>\n",
       "      <td>222.597305</td>\n",
       "      <td>575.434509</td>\n",
       "      <td>276.313263</td>\n",
       "      <td>0.680799</td>\n",
       "      <td>32</td>\n",
       "      <td>sports ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.816004</td>\n",
       "      <td>2.875185</td>\n",
       "      <td>179.255661</td>\n",
       "      <td>156.900909</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62.306839</td>\n",
       "      <td>37.029610</td>\n",
       "      <td>475.574402</td>\n",
       "      <td>574.415161</td>\n",
       "      <td>0.551929</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>372.545837</td>\n",
       "      <td>41.006050</td>\n",
       "      <td>458.513824</td>\n",
       "      <td>160.103439</td>\n",
       "      <td>0.407366</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>761.674377</td>\n",
       "      <td>2.816778</td>\n",
       "      <td>904.759644</td>\n",
       "      <td>154.058960</td>\n",
       "      <td>0.371151</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>166.491089</td>\n",
       "      <td>11.366502</td>\n",
       "      <td>277.652435</td>\n",
       "      <td>162.670776</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>88.047607</td>\n",
       "      <td>451.513336</td>\n",
       "      <td>138.721191</td>\n",
       "      <td>580.335632</td>\n",
       "      <td>0.301910</td>\n",
       "      <td>39</td>\n",
       "      <td>bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>372.656464</td>\n",
       "      <td>140.809448</td>\n",
       "      <td>401.705414</td>\n",
       "      <td>174.084229</td>\n",
       "      <td>0.261819</td>\n",
       "      <td>67</td>\n",
       "      <td>cell phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          xmin        ymin        xmax        ymax  confidence  class  \\\n",
       "0   487.388611   46.844364  792.064331  575.851929    0.899190      0   \n",
       "1   781.720581  241.722565  889.911133  379.067932    0.792831      0   \n",
       "2   434.312683    5.349050  620.991882  156.600708    0.777548      0   \n",
       "3   538.909790  222.597305  575.434509  276.313263    0.680799     32   \n",
       "4    31.816004    2.875185  179.255661  156.900909    0.577781      0   \n",
       "5    62.306839   37.029610  475.574402  574.415161    0.551929      0   \n",
       "6   372.545837   41.006050  458.513824  160.103439    0.407366      0   \n",
       "7   761.674377    2.816778  904.759644  154.058960    0.371151      0   \n",
       "8   166.491089   11.366502  277.652435  162.670776    0.358397      0   \n",
       "9    88.047607  451.513336  138.721191  580.335632    0.301910     39   \n",
       "10  372.656464  140.809448  401.705414  174.084229    0.261819     67   \n",
       "\n",
       "           name  \n",
       "0        person  \n",
       "1        person  \n",
       "2        person  \n",
       "3   sports ball  \n",
       "4        person  \n",
       "5        person  \n",
       "6        person  \n",
       "7        person  \n",
       "8        person  \n",
       "9        bottle  \n",
       "10   cell phone  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
    "\n",
    "# Image\n",
    "im = \"../toy_images/VS3GTLSXHRGTXIFMADIVVC6DEQ.jpg\"\n",
    "\n",
    "# Inference\n",
    "results = model(im)\n",
    "\n",
    "results.pandas().xyxy[0]\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/juagudelo/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-11-21 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA T1000 8GB, 7975MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "/home/juagudelo/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "image 1/1: 4608x2592 1 person\n",
      "Speed: 142.8ms pre-process, 19.6ms inference, 1.5ms NMS per image at shape (1, 3, 640, 384)\n",
      "Saved 1 image to \u001b[1mruns/detect/exp2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2473.486572</td>\n",
       "      <td>318.671814</td>\n",
       "      <td>2521.940186</td>\n",
       "      <td>404.910095</td>\n",
       "      <td>0.272107</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          xmin        ymin         xmax        ymax  confidence  class    name\n",
       "0  2473.486572  318.671814  2521.940186  404.910095    0.272107      0  person"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
    "\n",
    "# Images\n",
    "im1 = Image.open(\"../toy_images/vibrance.jpg\")  # PIL image\n",
    "\n",
    "# Inference\n",
    "results = model(im1, size=640)  # batch of images\n",
    "\n",
    "# Results\n",
    "results.print()\n",
    "results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # im1 predictions (tensor)\n",
    "results.pandas().xyxy[0]  # im1 predictions (pandas)\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wheat_head",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
